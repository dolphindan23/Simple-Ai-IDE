Since SimpleAide is a **Node/TS + Vite** app and your `package.json` currently has **no dedicated test runner** (no `test` script, no vitest/jest), the best “make sure it runs well” coverage is:

1. **static correctness** (types + build)
2. **runtime boot + DB sanity**
3. **SSE + events contract smoke**
4. **end-to-end run smoke** (Plan/Implement/Test/Review) verifying the new visibility features actually fire

Here’s the exact checklist I’d run every time you touch the agent visibility system.

---

## 1) Typecheck (catches most regressions fast)

```bash
npm run check
```

**This should catch:**

* AgentProfile type mismatch (frontend vs backend)
* missing `done` status union updates
* event payload shape drift

---

## 2) Production build (catches bundling/ESM/CJS breakage)

```bash
npm run build
```

Then boot production build:

```bash
npm run start
```

If `start` fails, you’ve got a deployment-grade issue (imports, dist path, ESM/CJS mismatch, missing env, etc.).

---

## 3) Dev boot smoke (UI + server actually load)

```bash
npm run dev
```

Open the app and confirm:

* Sidebar loads
* AI Team panel renders
* No red console errors (React, hooks, SSE reconnect loops)

---

## 4) DB schema sanity (especially after adding fields)

If you use Drizzle migrations/kit for schema updates:

```bash
npm run db:push
```

Then restart `npm run dev` to confirm:

* agent_profiles includes your new columns
* ai_run_events inserts don’t fail due to schema drift

---

## 5) SSE + event stream smoke (this validates the new “visibility” work)

### A) Confirm SSE endpoint streams

In a second terminal while the app is running:

```bash
curl -N http://localhost:PORT/api/ai/stream
```

You should see:

* an initial “init” payload / snapshot event
* periodic heartbeat
* new events as runs execute

*(If you’re using the per-run SSE endpoint, use that instead once you have a run id.)*

### B) Validate event types appear

During a run (see next section), confirm you see at least:

* `AGENT_STATUS` transitions including **done**
* `STEP` events including your `[phase] message (X/Y)`
* `READ_FILE` during snapshot
* `WRITE_FILE` when patch applied
* `TOOL_CALL` when verification runs
* `PROPOSE_CHANGESET` when diff generated

If those don’t appear in the curl stream, the UI can’t show them reliably.

---

## 6) End-to-end “run smoke” (the most important test)

Do one simple deterministic task that triggers your whole pipeline without being risky:

### Recommended smoke prompt

**Implement mode task (safe):**

> “Add a small comment in a non-critical file (or update a README line) and run verification.”

**Why:** guarantees snapshot → patch → verify → changeset events fire.

### What to verify in UI (this is your acceptance test)

In the AI Team sidebar while the run executes:

**Agent roster**

* shows correct agent per mode
* status transitions: `idle → working → done` (or waiting/error)
* model badge shows the configured model string

**Timeline**

* shows `[implement] … (1/4)` style progress steps
* shows many `READ_FILE` entries during snapshot (not just STEP)
* shows `WRITE_FILE` entries on patch apply
* shows `TOOL_CALL` for tests (even if it’s a no-op command)
* ends with a changeset proposed event (if implement generates diff)

**SSE robustness**

* refresh the page mid-run → timeline should rehydrate (init snapshot + subsequent events)
* disconnect/reconnect (or stop/start server) → UI should recover and continue appending

---

## 7) (Optional but very worth it) Add a quick automated smoke script

Since you don’t have a test runner yet, add a simple Node script (no dependencies) that:

* starts the server
* opens SSE stream
* triggers a trivial run via API
* asserts it receives required event types within N seconds

If you want, I can draft this “smoke runner” script based on your actual endpoints so you can run:

```bash
node script/smoke-ai-visibility.mjs
```

…and it will fail loudly if `done`, `READ_FILE`, `WRITE_FILE`, `TOOL_CALL`, etc. don’t arrive.

---

## What I’d add next (smallest investment to get real tests)

If you want a proper CI-grade suite, add:

* **vitest** (unit tests)
* **supertest** (API tests)
* a single integration test that validates SSE + event ordering

But for right now, the commands above + the run smoke is the practical “it won’t break in production” set.

---

If you tell me what port you run on and confirm the exact endpoints you use to start a run (Plan/Implement/Test), I’ll give you **copy-paste curl commands** for a fully automated “run + assert event types” smoke test.
